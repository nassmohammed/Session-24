{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375cee36-9603-4b9e-b445-ccc9496ef2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.special import gammaincinv, gammainc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8ff4fa-f0c5-4c33-bd57-43bb3d4d0a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from convenience_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b7cc72-5db3-4c4c-aaa8-87579d530ed1",
   "metadata": {},
   "source": [
    "# Problem 1: Simulating a single frame exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4706853-c0cf-4626-9877-2bd08216d177",
   "metadata": {},
   "source": [
    "## [1a] Simulate a star with a Gaussian PSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043a0699-ce2b-4ae1-a3ab-38fb320ff23e",
   "metadata": {},
   "source": [
    "Before we can start thinking about coaddition and difference imaging, we need a (simulated) single frame exposure. For our purposes, let's think just about a single point source with a Gaussian profile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b2f9a2-6baf-4bfc-b2af-7df0c0275a9f",
   "metadata": {},
   "source": [
    "First, write a function that returns a two-dimensional Gaussian for a grid of pixels (y,x):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b1ff7-471b-4222-9af8-0aab43912a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian2d(x, y, m, s):\n",
    "    '''\n",
    "    2D axisymmetric Gaussian profile, normalized such that the function integrates to unity.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x, y : array-like\n",
    "        Coordinate arrays\n",
    "    m : array-like\n",
    "        Center coordinates\n",
    "    s : float\n",
    "        Standard deviation (same for both x and y)\n",
    "    '''\n",
    "    # return your 2D Gaussian profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d3a5a-ada8-441c-a2a0-a79deb3e6062",
   "metadata": {},
   "source": [
    "Now, let's write a function that creates a mock exposure for a star of fixed brightness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee45e8c5-ffe3-4fb1-97f3-276af814cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_exposure ( exptime, star_count_rate=100., sky_count_rate=1., fwhm=20., imsize=128 ):\n",
    "    '''\n",
    "    Take a mock exposure for a specified exposure time (in seconds), given the total \n",
    "    count rate from a point source-like object and a sky brightness.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    exptime : float\n",
    "        exposure time, in seconds\n",
    "    star_count_rate : float\n",
    "        total counts coming from a point-source-like object\n",
    "    sky_count_rate : float\n",
    "        total counts per pixel coming from the sky background\n",
    "    fwhm : float\n",
    "        Gaussian FWHM of the PSF, in pixels\n",
    "    imsize : int\n",
    "        exposure size (N=M=imsize)\n",
    "    '''\n",
    "    y,x = np.mgrid[:imsize+1,:imsize+1]\n",
    "    xc = imsize//2\n",
    "    yc = imsize//2\n",
    "\n",
    "    psf_std = # convert Gaussian FWHM to standard deviation\n",
    "    star = gaussian2d(x,y,'normalize',(xc,yc),psf_std)) # stellar photon rate as a function of position\n",
    "    total_count = exptime * star_count_rate # total stellar photons\n",
    "    star *= total_count\n",
    "    sky = # total sky photons\n",
    "    signal = # total observed photons\n",
    "    observed_signal = # draw from a noise profile where the standard deviation is the square root of signal \n",
    "    return observed_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61de1e99-abf0-4af4-81f9-395405ddecc5",
   "metadata": {},
   "source": [
    "Now let's visualize what the exposure looks like at various exposure times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe207761-ccc1-4bf1-a39d-e6eeadd4f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,3,figsize=(12,4))\n",
    "\n",
    "for logtexp in np.arange(1,4):\n",
    "    our_imshow(take_exposure(10.**logtexp), q=0., ax=axarr[logtexp-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e033e039-6169-40bb-86e8-20ee05de5707",
   "metadata": {},
   "source": [
    "## [1b] Recover the expected SNR scaling with exposure time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f735df7-f89e-41c8-8867-209b58894a98",
   "metadata": {},
   "source": [
    "In the case where each exposure's noise and source properties are the same, we expect the SNR to scale as $\\sqrt{t_{\\rm exp}}$. Let's check that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b2d8b-54c0-4188-acf1-5ab33be6c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "logtexp_array = np.arange(0., 4, 0.1)\n",
    "star_count_rate = 100.\n",
    "\n",
    "sky_sample = # \\\\ let's make an empirical estimate of the noise in each exposure using the standard deviation in a blank patch of expsoure\n",
    "star_counts = # \\\\ and we know what the total counts from the star should be, given the exposure time.\n",
    "\n",
    "plt.plot(\n",
    "    10.**logtexp_array,\n",
    "    # \\\\ expected scaling with exposure time here!\n",
    "    label=r'SNR$_0\\sqrt{t_{\\rm exp}\\times S}$',\n",
    "    color='k',\n",
    "    lw=3\n",
    ")\n",
    "plt.scatter(\n",
    "    10.**logtexp_array,\n",
    "    # \\\\ empirical measure of SNR here!\n",
    "    label='SNR',\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('exposure time (seconds)')\n",
    "plt.ylabel('SNR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ef3017-39d4-4beb-92be-396278d635a5",
   "metadata": {},
   "source": [
    "# Problem 2: Build a coadd from homogeneous data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3f4544-7cdd-4553-b8fb-928b5e3ca4c4",
   "metadata": {},
   "source": [
    "## [2a] Build a mean-weighted coadd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbc8ff3-3bea-4202-85d6-7391b0825486",
   "metadata": {},
   "source": [
    "Now that we can \"take\" single frame exposures, let's start making some coadds -- first, in the case where all exposure are taken under identical conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e0d8fa-92ce-4b36-b549-24c07017de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "texp = 10.\n",
    "star_count_rate = 100.\n",
    "exposures = np.array([ take_exposure(texp, star_count_rate) for _ in range(100) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5feeb-77cb-40d9-9fa8-47ecea2a6a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_coadd = # make a mean coadd for the exposure stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24ff54a-bcf8-4055-9da4-938d69204b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,3,figsize=(12,4))\n",
    "our_imshow(exposures[0], ax=axarr[0], cmap='viridis')\n",
    "our_imshow(mw_coadd, ax=axarr[1], cmap='viridis')\n",
    "\n",
    "px = np.arange(exposures[0].shape[1])\n",
    "# \\\\ here, show the collapsed 1D profile of a single exposure and the mean coadd\n",
    "axarr[2].scatter(\n",
    "    px,\n",
    "    # single exposure 1D profile here\n",
    "    color='grey'\n",
    ")\n",
    "axarr[2].scatter(\n",
    "    px,\n",
    "    # mean coadd 1D profile here\n",
    "    color='tab:red'\n",
    ")\n",
    "axarr[2].set_xlabel('pixel index')\n",
    "axarr[2].set_ylabel('counts')\n",
    "\n",
    "our_text(0.025,0.975, 'single frame exposure', color='lightgrey', ax=axarr[0], fontsize=15, bordercolor='k', borderwidth=3)\n",
    "our_text(0.025,0.975, 'coadd', color='tab:red', ax=axarr[1], fontsize=15, bordercolor='w', borderwidth=3)\n",
    "\n",
    "\n",
    "plt.tight_layout ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d179356-4eb5-4e49-b1cd-b001e123dcf0",
   "metadata": {},
   "source": [
    "## [2b] Plot coadd depth as a function of the number of coadded images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a06dd0-d755-42d1-8f1b-2249237cf504",
   "metadata": {},
   "source": [
    "For this set-up, we also expect the coadd depth (SNR) to scale as $\\sqrt{D}$, where $D$ is the number of exposures going into the stack. Let's check that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe03d2-0486-4c62-85af-757d302566a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nstack = np.arange(1, len(exposures)+1)\n",
    "stack_snr = np.zeros(nstack.shape)\n",
    "star_counts = # total counts expected from the point source (exposure time * count_rate)\n",
    "\n",
    "for n in nstack:\n",
    "    coadd = # make mean coadd\n",
    "    sky_sample = # empirical estimate of background uncertainty\n",
    "    stack_snr[n-1] = # record observed SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8abb4-588f-408a-8a89-a6e7ff5941be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "plt.plot(\n",
    "    nstack,\n",
    "    # expected scaling of SNR here!\n",
    "    label=r'SNR$_0\\sqrt{N_{\\rm exp}}$',\n",
    "    color='k',\n",
    "    lw=3,\n",
    "    ls='--'\n",
    ")\n",
    "plt.scatter(\n",
    "    nstack,\n",
    "    # observed scaling of SNR here\n",
    "    label='SNR',\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Number of exposures')\n",
    "plt.ylabel('SNR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58045c72-779b-4680-a214-175e70db54e8",
   "metadata": {},
   "source": [
    "# Problem 3: Build weighted coadds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0989559-bc7e-4984-b124-694643c0a4c4",
   "metadata": {},
   "source": [
    "In the real world, unfortunately, our observing conditions are not homogeneous -- therefore, we want a way to make coadds that take advantage of exposures taken under good conditions and downweight exposures taken under poor conditions. Let's consider two simple cases for making weighted coadds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b40ba22-57cf-46ea-a368-9c678c469bde",
   "metadata": {},
   "source": [
    "## [3a] Variable sky transparency\n",
    "\n",
    "First let's consider a case where the sky background changes from one exposure to another. Now, we'll add another step (background subtraction) and construct an inverse variance-weighted coadd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb7922b-25ac-469a-b03f-f5026c73048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\\\ let's make two populations of exposures: one set taken under good conditions, the other under bad conditions\n",
    "sky_bg = np.concatenate([np.random.uniform(1., 2., 50), np.random.uniform(50,100.,50)])\n",
    "star_count_rate = 300.\n",
    "exposures = [ take_exposure(10., star_count_rate, sky_count_rate) for sky_count_rate in sky_bg ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659105f-023a-40a1-b2ca-b019816aa708",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_variance = # estimate of the per-exposure variance (should be a vector of length D)\n",
    "weights = # inverse-variance weights for the exposures\n",
    "\n",
    "bkg_subtracted_exposures = # subtract off the mean per-expsoure background\n",
    "unweighted_coadd = # make a mean coadd\n",
    "invvarweighted_coadd = # make an inverse variance-weighted coadd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0bae9e-e3c6-42a4-871d-b5372a87773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,3,figsize=(12,4))\n",
    "our_imshow(unweighted_coadd, ax=axarr[0], cmap='viridis')\n",
    "our_imshow(invvarweighted_coadd, ax=axarr[1], cmap='viridis')\n",
    "\n",
    "px = np.arange(exposures[0].shape[1])\n",
    "axarr[2].scatter(px,np.sum(unweighted_coadd,axis=0), color='grey')\n",
    "axarr[2].scatter(px,np.sum(invvarweighted_coadd,axis=0), color='tab:red')\n",
    "axarr[2].set_xlabel('pixel index')\n",
    "axarr[2].set_ylabel('counts')\n",
    "\n",
    "our_text(0.025,0.975, 'unweighted coadd', color='lightgrey', ax=axarr[0], fontsize=15, bordercolor='k', borderwidth=3)\n",
    "our_text(0.025,0.975, 'weighted coadd', color='tab:red', ax=axarr[1], fontsize=15, bordercolor='w', borderwidth=3)\n",
    "\n",
    "\n",
    "plt.tight_layout ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f55f84-c965-41c1-af32-2e82a20943d2",
   "metadata": {},
   "source": [
    "# Problem 4: Artifacts and read noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1448d5c2-e01b-46f6-a00f-0f83e998f593",
   "metadata": {},
   "source": [
    "Now let's take a brief dive into handling imaging artifacts! A common type of artifact is from cosmic rays, when charged particles strike the CCD and create a bright, highly linear pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e787cf23-758b-4f1e-a57d-7ced6e619ce2",
   "metadata": {},
   "source": [
    "## [4a] Simulate single frame exposures with read noise and cosmic rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1564acf3-1acc-44fb-8642-020a1ed0bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cosmic_ray ( flux, x0, y0, m, dx, imsize ):\n",
    "    y,x = np.mgrid[:imsize+1,:imsize+1]\n",
    "    x_cr = np.arange(x0, x0+dx)\n",
    "    y_cr = # flag pixels in a line described by y = m*(x-x0) + y0\n",
    "    # \\\\ don't allow the line to run off the array\n",
    "    img = # make image with CR hit\n",
    "    return img\n",
    "    \n",
    "def take_exposure_p4 ( exptime, star_count_rate=100., sky_count_rate=1., fwhm=20., imsize=128, read_noise=10., cr_rate=0.01, cr_flux=100. ):\n",
    "    '''\n",
    "    The same as take_exposure, but now with cosmic rays hitting the detector probabilistically.\n",
    "    '''\n",
    "    y,x = np.mgrid[:imsize+1,:imsize+1]\n",
    "    xc = imsize//2\n",
    "    yc = imsize//2\n",
    "    \n",
    "    star = gaussian2d(# \\\\ add star and background, as for take_exposure\n",
    "\n",
    "    ncr = # \\\\ add a randomly generated number of cCR hits based on cr_rate, which is defined as the\n",
    "        # \\\\ average number of event per second\n",
    "    cosmic_rays = np.zeros(star.shape)\n",
    "    for _ in range(ncr):\n",
    "        x0 = # draw x0\n",
    "        y0 = # draw y0\n",
    "        dx = # draw length\n",
    "        m = # draw slope\n",
    "        cosmic_rays += add_cosmic_ray(cr_flux, x0,y0,m,dx,imsize)\n",
    "    \n",
    "    signal = star + sky + cosmic_rays\n",
    "   \n",
    "    observed_signal = # simulate signal\n",
    "    observed_signal_wreadnoise = # add read noise\n",
    "    return observed_signal_wreadnoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83890bb9-6fce-4c00-aa3d-d170ed026d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,2,figsize=(10,4))\n",
    "our_imshow(take_exposure_p4(20., star_count_rate=100., ),  cmap='viridis', ax=axarr[0])\n",
    "our_imshow(take_exposure_p4(600., star_count_rate=100., ), cmap='viridis',  ax=axarr[1])\n",
    "\n",
    "our_text(0.025,0.975, 'short exposure', color='tab:red', ax=axarr[0], fontsize=15, bordercolor='w', borderwidth=3)\n",
    "our_text(0.025,0.975, 'long exposure', color='tab:red', ax=axarr[1], fontsize=15, bordercolor='w', borderwidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f5459b-54a5-49cc-a0a5-90d6599e1186",
   "metadata": {},
   "source": [
    "So you might say -- let's just take a ton of short exposures! Then we'll have fewer cosmic rays to deal with, and more exposures to use to filter them out. At very short exposure times, however, you can become read noise dominated. To illustrate this, let's take two sky exposures of different exposure times, then compare their background-subtracted profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df98df1-bf5b-47d0-8ccf-c3bb45504c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_exp = take_exposure_p4(3600., star_count_rate=0., cr_rate=0.,read_noise=10.)\n",
    "short_exp = take_exposure_p4(5., star_count_rate=0., cr_rate=0.,read_noise=10.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd0e7bc-fdd8-43df-8cdc-aba708afd01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_exp.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088c212d-ffed-418e-b555-5247c85041c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_exp.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041bd239-98c5-4ae5-8a9a-203cd847a1ba",
   "metadata": {},
   "source": [
    "## [4b] Cosmic ray detection on a single exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37361c2c-bf58-43df-98d1-db2e4a5755f2",
   "metadata": {},
   "source": [
    "In this section we'll implement a simplified version of the cosmic ray detection used in HSC-SSP data processing, which itself is the precursor to the LSST science pipelines. We're going to put these cosmic rays in the vicinity of a very bright star to better illustrate the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3d467-bfd7-4205-804d-5ca09ad391e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e465827-49a0-40e9-9a39-977a2de18e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sky_count_rate = 1.\n",
    "exptime = 50.\n",
    "exposure_nosky = take_exposure_p4(50., star_count_rate=1e4, sky_count_rate=0., cr_flux=800, cr_rate=0.025)\n",
    "sky_bg = np.random.normal(sky_count_rate*exptime, np.sqrt(sky_count_rate*exptime), exposure_nosky.shape)\n",
    "exposure = exposure_nosky + sky_bg\n",
    "our_imshow(exposure) # \\\\ verify visually that you have at least 1 CR in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23792228-fe43-4efe-a15f-d5654b9238d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "too_bright_factor = 6.\n",
    "is_too_bright = # flag pixels above a factor of too_bright_factor of the sky background\n",
    "our_imshow(is_too_bright.astype(float), cmap='viridis', q=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df87fa02-0be9-49dd-bb41-bb532d09da3e",
   "metadata": {},
   "source": [
    "To find the cosmic rays morphologically, we'll use a simplified version of the algorithm originally implemented for SDSS. Essentially, we take the gradient of exposure in different directions and search for peaks that are sharper than what is allowed by the PSF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780032c6-15fd-4c38-9b4a-ab89295f3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_v0 = # vertical gradient\n",
    "grad_v1 = # vertical gradient in the opposite direction\n",
    "grad_h0 = # horiziontal gradient\n",
    "grad_h1 = # horizontal gradient in the opposite direction\n",
    "gradients = [grad_v0, grad_v1, grad_h0, grad_h1]\n",
    "\n",
    "std = # convert Gaussian FWHM to standard deviation\n",
    "psf_diff = # estimate what the PSF fall-off would be at teh same distance as the scale over which the gradient was computed\n",
    "\n",
    "too_sharp_factor = 6.\n",
    "cr_masks = [ grad > (too_sharp_factor*exposure*psf_diff) for grad in gradients]\n",
    "morphology_mask = np.sum(cr_masks,axis=0)\n",
    "\n",
    "cosmic_ray_mask = is_too_bright & (morphology_mask > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8bde5c-a79c-4c5b-9511-2aab626ebcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,3,figsize=(12,4))\n",
    "our_imshow(exposure, ax=axarr[0])\n",
    "axarr[1].imshow(cosmic_ray_mask, origin='lower')\n",
    "our_imshow(np.where(cosmic_ray_mask, np.random.normal(0., sky_count_rate*exptime, cosmic_ray_mask.shape), exposure), ax=axarr[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6426e526-f5e1-4c6e-864b-02a535ffb671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
