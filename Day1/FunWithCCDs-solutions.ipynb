{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e2fb37f-6bf5-44f3-9f41-704b96e69e4d",
   "metadata": {},
   "source": [
    "# Fun with CCDs\n",
    "\n",
    "**LSST-DA Data Science Fellowship Program**\n",
    "\n",
    "*By Alex Drlica-Wagner*\n",
    "\n",
    "This set of exercises is intended to get you familiar with some of the intricacies of working with images from CCDs. This may be the only time you touch raw LSST images (well, actually DP1 images from LSSTComCam, but close enough). The goal is to get a sense for the \"warts and pimples\" in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d148b1-94fb-4508-b899-b2e4cae5dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic python packages\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set a standard figure size to use\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcd6e5d-c1bc-4ec6-b4e0-bd58e8c9ece4",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "\n",
    "This section goes through how to access a raw image from the butler. You don't need to know what is going on under the hood here, just think of this as a way to access a non-local file server. **If you don't have access to the [Rubin Science Platform](https://data.lsst.cloud/), please contact the instructor!**\n",
    "\n",
    "If at some point you are interested in more details about accessing the raw images, you can check out the associated tutorial notebook: [202.5. Raw images](https://dp1.lsst.io/tutorials/notebook/202/notebook-202-5.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d1a444-21b7-4709-8632-829ce3123a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSST Science Pipelines (Stack) packages\n",
    "import lsst.daf.butler as dafButler\n",
    "import lsst.afw.display as afwDisplay\n",
    "\n",
    "# The DP1 data lives in a butler collection.\n",
    "config = \"dp1\"\n",
    "collections = \"LSSTComCam/DP1\"\n",
    "butler = dafButler.Butler(config, collections=collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc09a4e-b3a8-4013-a976-3d12c0b36be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't know what raw data exists, so let's print a few dataRefs...\n",
    "refs = butler.query_datasets('raw')\n",
    "for ref in refs[:10]:\n",
    "    print(ref.dataId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07320906-1e3f-4686-b6c2-937d64993e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We choose the CCD image that we want to grab.\n",
    "# The LSSTComCam focal plane contains 9 CCDs\n",
    "dataId = {'instrument': 'LSSTComCam', 'detector': 1, 'exposure': 2024120200065, 'band': 'g'}\n",
    "#dataId = {'instrument': 'LSSTComCam', 'detector': 1, 'exposure': 2024120200066, 'band': 'g'}\n",
    "print(dataId)\n",
    "\n",
    "# Now we get the raw image, which is an ExposureF object\n",
    "print(\"Getting raw...\")\n",
    "raw = butler.get('raw', dataId)\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af497d43-8cb4-4d69-91f5-b6b21811d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save the image to a FITS file.\n",
    "outfile = f\"{dataId['instrument']}_{dataId['exposure']}_{dataId['detector']:03d}_{dataId['band']}_raw.fits\"\n",
    "print(outfile)\n",
    "print(f\"Writing {outfile}...\")\n",
    "raw.writeFits(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a2e5b4-7c5d-4e18-871f-82e93f79ac24",
   "metadata": {},
   "source": [
    "## Exercise 1. Exploring the Image\n",
    "\n",
    "The following set of questions asks you to visualize and investigate the pixel information in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47517e14-00b0-4263-bdfa-f5ca9e5ffd2b",
   "metadata": {},
   "source": [
    "### Visualize the image\n",
    "\n",
    "**Option 1:** If you are familiar with the standard FITS image viewer tool [SAOImageDS9](https://sites.google.com/cfa.harvard.edu/saoimageds9) (commonly known as `ds9`), then probably the easiest way to view the image is to download it and view it with ds9 locally. If you don't have `ds9` on your machine, you can download it for most systems using the link above.\n",
    "\n",
    "* Execute the cells above to save the image to a FITS file.\n",
    "* Download the FITS file by right clicking on the icon associated with the file in the File Browser (to the left of this notebook) and select \"Download.\n",
    "* Open the FITS file with ds9. You can do this from the ds9 GUI menu with \"File\" -> \"Open\", or from the command line with:\n",
    "\n",
    "```\n",
    "ds9 LSSTComCam_2024120200065_001_g_raw.fits\n",
    "```\n",
    "\n",
    "**Option 2:** You can view the image interactively using the Firefly visualization interface. To do this, execute the following code in a cell. This should open a new notebook tab with a firefly frame and that displays the raw image.\n",
    "\n",
    "```\n",
    "afwDisplay.setDefaultBackend('firefly')\n",
    "afw_display = afwDisplay.Display(frame=1)\n",
    "afw_display.image(raw.image)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b36b83-a185-4567-b0aa-739a52c619b8",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight: bold;\">Exercise:</span> How many sections is the image divided into?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47a96d0-29a5-4892-b36f-7f75470b1d60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T05:26:48.384929Z",
     "iopub.status.busy": "2025-09-14T05:26:48.384363Z",
     "iopub.status.idle": "2025-09-14T05:26:48.390356Z",
     "shell.execute_reply": "2025-09-14T05:26:48.389588Z",
     "shell.execute_reply.started": "2025-09-14T05:26:48.384901Z"
    }
   },
   "source": [
    "<span style=\"color:red\">The CCD is devided into 16 amplifiers.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887df8d1-606e-4c12-b7d3-0446ac89e84a",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight: bold;\">Excercise:</span> Why is it difficult to visualize all the section at the same time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afbf2e7-78e0-4aba-af28-96c29f2dc07e",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">The baseline (bias level) of each amplifier is different.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad06648-d1a7-4ed5-ba36-79aed40aac23",
   "metadata": {},
   "source": [
    "### Identify artifacts\n",
    "\n",
    "The next set of questions asks you to identify examples of several different artifacts in the image. \n",
    "\n",
    "* **Saturation**: when the amount }of charge in a pixel exceeds the maximum amount that can be confined to the pixel (i.e., the \"full well\").\n",
    "* **Bleed trail**: electrons from a super-saturated source that start to \"bleed\" away from that source.\n",
    "* **Crosstalk**: electronic signals from a bright \"agressor\" in one amplifier that can be seen in pixels of \"victim\" amplifiers that were read out at the same time.\n",
    "* **Cosmic ray**: energetic charged particle that has penetrated the CCD and left an ionization trail\n",
    "* **Bad pixel(s)**: one or a small group of pixels with an abnormal response.\n",
    "* **Bad column**: a defect in the CCD pixel array that can either be bright (producing excess charge) or dark (trapping charge).\n",
    "* **Bias dip**: the electronic bias level can change within an image introducing apparent dips and features in the background level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859844fa-c73e-4ae4-8cae-5a3999078a67",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight: bold;\">Exercise:</span> Make a copy of the slides you find [here](https://docs.google.com/presentation/d/1E4QCea72qiVExO_G8DiDuLRe-wKOfRL9njHUHDwMsjY). There is one slide for each of the following artifacts. Insert a screenshot showing an example of the artifact and complete the associated questions on the slide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528abfc0-8081-45f1-b0b3-632fc3108f10",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> Link to your slides here...</span> [link](https://docs.google.com/presentation/d/1InVXtndzobxizIurGfZY8vXcTBXIqzQREzXYfOG-VEo/edit?slide=id.p#slide=id.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daafd00f-f337-4969-a9d4-924d4d8cc290",
   "metadata": {},
   "source": [
    "## Exercise 2. Overscan Bias Correction\n",
    "\n",
    "In this question we are going to isolate the part of the image showing pixels that were exposed to the sky and use the overscan region to correct for the major electronic effects introduced by the amplifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa8cb2-e819-4cf6-b7d8-455dacff90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the default plotting backend to matplotlib\n",
    "afwDisplay.setDefaultBackend('matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3884c4cc-96aa-4ba1-a2f4-9b4806eb7089",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight: bold;\">Exercise:</span> Use matplotlib to plot the full raw image. Play with the `vmin` and `vmax` parameters until you can see astronomical objects in almost every section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52cea6-59f3-4334-8b4c-335a7b90bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw.image.array\n",
    "vmin,vmax = np.percentile(data, [0.25,99.91])\n",
    "plt.imshow(data, origin='lower', cmap='gray', norm='log', vmin=vmin, vmax=vmax, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2e6337-4324-45bc-8602-7d11e5391c2c",
   "metadata": {},
   "source": [
    "Divide the image into amplifier sections. Note that in the above image, the origin (0, 0) is in the lower left corner so the bottom amplifiers have row index 0 and the top amplifiers have row index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1b21f-65fe-412a-bea0-d3eccfb60d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amplifier sections\n",
    "amp_nrow,amp_ncol = (2,8)\n",
    "ysize = data.shape[0] // amp_nrow\n",
    "xsize = data.shape[1] // amp_ncol\n",
    "amplifiers = dict()\n",
    "for j in range(amp_nrow):\n",
    "    ymin,ymax = j*ysize, j*ysize + ysize\n",
    "    for i in range(amp_ncol):\n",
    "        xmin,xmax = i*xsize, i*xsize + xsize\n",
    "        amplifiers[f'amp{j}{i}'] = data[ymin:ymax,xmin:xmax].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f09ec90-32ed-417c-961c-6cd6c1a2fd26",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight: bold;\">Exercise:</span> Use matplotlib to plot amplifier 05 (`amp05`). Set the vmin/vmax scale so that you can see stars and galaxies. Answer the following questions:\n",
    "* Where is the serial overscan?\n",
    "* Where is the vertical overscan?\n",
    "* In which corner is the readout amplifier located?\n",
    "* Why are the overscan region much darker than the image of the sky?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951ac906-8ab9-4de9-b443-a77c72c5a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here...\n",
    "\n",
    "# Adjust vmin and vmax here.\n",
    "amp = amplifiers['amp05']\n",
    "vmin,vmax = np.percentile(amp, [10,99.7])\n",
    "plt.imshow(amp, origin='lower', norm='log',cmap='gray', vmin=vmin, vmax=vmax)\n",
    "\n",
    "print(\"Serial overscan is dark region on the left\")\n",
    "print(\"Parallel overscan is dark region on the bottom\")\n",
    "print(\"Readout amplifier located at top right\")\n",
    "print(\"There are no sky counts in the overscan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e4b5bf-c101-432b-9e27-f03be494b5e0",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight: bold;\">Excercise:</span> Use matplotlib to plot just the serial overscan and just the parallel overscan regions of amplifier 05 (`amp05`). Do you see more structure in the serial or parallel overscan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a067b57-1a2f-496f-8056-906bdd83afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here...\n",
    "\n",
    "# I'm estimating the extent of the overscan by eye...\n",
    "#Serial Overscan: columns 0 to 64\n",
    "#Parallel Overscan: rows 2000 to 2048\n",
    "\n",
    "# If you want to get the values of these quantities for an LSST detector\n",
    "#detector = raw.getDetector()\n",
    "#amplifiers = det.getAmplifiers()\n",
    "#amplifier = amplifiers[15]\n",
    "#print(amplifier.getRawSerialOverscanBBox())\n",
    "#print(amplifier.getRawSerialPrescanBBox())\n",
    "#print(amplifier.getRawParallelOverscanBBox())\n",
    "\n",
    "serial_os = amp[:,:64].copy()\n",
    "parallel_os = amp[2000:2048, :].copy()\n",
    "\n",
    "plt.figure()\n",
    "vmin,vmax = np.percentile(serial_os[:2000, :], [5,95])\n",
    "plt.imshow(serial_os, origin='lower', norm='log', cmap='gray',vmin=vmin,vmax=vmax)\n",
    "plt.ylabel(\"Serial Overscan\")\n",
    "\n",
    "plt.figure()\n",
    "vmin,vmax = np.percentile(parallel_os[:, 64:], [5,95])\n",
    "plt.imshow(parallel_os, origin='lower', norm='log', cmap='gray',vmin=vmin,vmax=vmax)\n",
    "plt.xlabel(\"Parallel Overscan\")\n",
    "\n",
    "print(\"There is more structure in the parallel overscan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a3aa8-b0f9-43d0-a692-b14129348947",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight: bold;\">Exercise:</span> Calculate the median for each column of the parallel overscan and subtract it from each column of the science image. Does the resulting science image look better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4febed43-6724-4d15-b9c4-7423f010830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here...\n",
    "\n",
    "median_overscan = np.median(parallel_os,axis=0)\n",
    "mean_overscan = np.mean(parallel_os,axis=0)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(median_overscan)\n",
    "plt.plot(mean_overscan)\n",
    "plt.ylim(*np.percentile(median_overscan, [1,99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39b5df6-88fa-49f1-9bff-89583220f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = amp[:2000,64:].copy() - mean_overscan[64:]\n",
    "vmin,vmax = np.percentile(image, [5,95])\n",
    "plt.imshow(image, origin='lower', cmap='gray', vmin=vmin,vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf965b8c-a3de-4b89-b67e-5ec11cc3420e",
   "metadata": {},
   "source": [
    "## Extra Credit. Stitch it all back together\n",
    "\n",
    "<span style=\"color:blue;font-weight: bold;\">Exercise:</span> For extra credit, use what we learned from the previous examples to stitch everything back together into a bias-corrected image. This can be done pretty efficiently with numpy.\n",
    "\n",
    "* Loop over the amplifiers in row 0. For each amplifier, perform the overscan bias correction. Keep only the on-sky region of the image (i.e., clip off the overscan) and append to an output list.\n",
    "* Use np.hstack to combine the amplifiers in your row 0 output list into a single array.\n",
    "* Do the same procedure for row 1 (note that the parallel overscan is on the opposite side of the image).\n",
    "* Use np.vstack to combine the array for row 0 and row 1.\n",
    "* Plot the resulting image.\n",
    "* What remaining features do you see? What could be causing them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8925ea1-cc54-4746-b537-a34adda618bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here...\n",
    "\n",
    "row0 = []\n",
    "for j in range(8):\n",
    "    amp = amplifiers[f'amp0{j}']\n",
    "    median_os = np.median(amp[2000:2048,:],axis=0)\n",
    "    data = (amp - median_os)[:2000,64:]\n",
    "    #data = (amp.copy() - np.median(amp[:,5:60],axis=1)[:,np.newaxis])[:2000,65:65+500]\n",
    "    row0.append(data)\n",
    "\n",
    "row1 = []\n",
    "for j in range(8):\n",
    "    amp = amplifiers[f'amp1{j}']\n",
    "    median_os = np.median(amp[0:48,:],axis=0)\n",
    "    data = (amp - median_os)[48:,64:]\n",
    "    row1.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fea1b-4efa-476d-8570-8c90ceff4305",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.vstack( [np.hstack(row0), np.hstack(row1)] )\n",
    "vmin,vmax = np.percentile(image, [5,95])\n",
    "plt.imshow(image, cmap='gray', origin='lower', vmin=vmin, vmax=vmax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
